{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Sample Bottleneck \n",
    "\n",
    "This notebook shows how to apply the Per-Sample Bottleneck to pretrained ImageNet models. \n",
    "\n",
    "Ensure that `./data/imagenet` points to your copy of the ImageNet dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision.models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from per_sample_bottleneck.per_sample_bottleneck import PerSampleBottleneck, insert_into_sequential\n",
    "from per_sample_bottleneck.utils import get_output_shapes, plot_heatmap, denormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_dir = 'data/imagenet/'\n",
    "\n",
    "dev = torch.device('cuda:0')\n",
    "\n",
    "# select a model to analyse\n",
    "# model = torchvision.models.vgg16(pretrained=True)\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "# model = torchvision.models.inception_v3(pretrained=True)\n",
    "model.eval()\n",
    "model.to(dev)\n",
    "\n",
    "# load the data\n",
    "if type(model) == torchvision.models.inception.Inception3:\n",
    "    image_size = 299\n",
    "else:\n",
    "    image_size = 224\n",
    "    \n",
    "valset = ImageFolder(\n",
    "    os.path.join(imagenet_dir, 'validation'),\n",
    "    transform=Compose([\n",
    "        CenterCrop(256), Resize(image_size), ToTensor(), \n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "trainset = ImageFolder(\n",
    "    os.path.join(imagenet_dir, 'train'),\n",
    "    transform=Compose([\n",
    "        CenterCrop(256), Resize(image_size), ToTensor(), \n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "with open('imagenet_class_index.json') as f:\n",
    "    idx2class = {int(k): v[1] for k, v in json.load(f).items()}\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
    "img, target = valset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the bottleneck into the model\n",
    "\n",
    "You can experiment with the location of the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = get_output_shapes(model, img[None].to(dev))\n",
    "\n",
    "\n",
    "if type(model) == torchvision.models.vgg.VGG:\n",
    "    size = sizes['features.17']\n",
    "    btln = PerSampleBottleneck(*size)\n",
    "    model.features = insert_into_sequential(model.features, btln, 18)\n",
    "elif type(model) == torchvision.models.resnet.ResNet:\n",
    "    size = sizes['layer2']\n",
    "    btln = PerSampleBottleneck(*size)\n",
    "    model.layer2 = nn.Sequential(model.layer2, btln)\n",
    "elif type(model) == torchvision.models.inception.Inception3:\n",
    "    size = sizes['Mixed_5b']\n",
    "    btln = PerSampleBottleneck(*size)\n",
    "    model.Mixed_5b = nn.Sequential(model.Mixed_5b, btln)\n",
    "\n",
    "if sum(type(m) == PerSampleBottleneck for m in model.modules()) > 1:\n",
    "    raise ValueError(\"You added multiple bottlenecks to the model.\")\n",
    "    \n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Mean and Variance\n",
    "\n",
    "Here, we estimate the mean and variances of the feature map. It is important for measuring the amount of information transmitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btln.estimate(model, trainloader, device=dev, n_samples=5000, progbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = (12, 3, 4)\n",
    "print(\"Neuron at position {:} has mean {:.2f} and std {:.2f}\".format(\n",
    "    neuron, btln.estimator.mean()[neuron],  btln.estimator.std()[neuron]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Heatmaps for some random samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 6))\n",
    "np.random.seed(0)\n",
    "for ax, sample_idx in zip(axes.flatten(), np.random.choice(50000, 10)):\n",
    "    img, target = valset[sample_idx]\n",
    "    img = img[None].to(dev)\n",
    "    \n",
    "    # execute the model on a given sample and return the target NLL\n",
    "    model_loss_closure = lambda x: -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "    \n",
    "    # generate the heatmap\n",
    "    heatmap = btln.heatmap(img, model_loss_closure)\n",
    "    \n",
    "    # plot the heatmap\n",
    "    plot_heatmap(heatmap, denormalize(img[0]),  ax=ax)\n",
    "    ax.set_title(idx2class[target])\n",
    "fig.suptitle(\"model: {}\".format(type(model).__name__))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(\"./monkeys.jpg\"))\n",
    "img = (img.transpose(2, 0, 1) / 255)\n",
    "target = 382  # 382: squirrel monkey\n",
    "\n",
    "# preprocess image\n",
    "img  = Compose([Resize(image_size), ToTensor(),  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])(Image.open(\"./monkeys.jpg\"))\n",
    "\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "heatmap = btln.heatmap(img[None].to(dev), model_loss_closure) \n",
    "ax = plot_heatmap(heatmap, denormalize(img))\n",
    "_ = ax.set_title(idx2class[target])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
