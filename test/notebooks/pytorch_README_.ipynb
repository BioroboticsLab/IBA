{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: IBA (Per-Sample Bottleneck)\n",
    "\n",
    "This notebook shows how to apply the Per-Sample Bottleneck to pretrained ImageNet models. \n",
    "\n",
    "Ensure that `./imagenet` points to your copy of the ImageNet dataset. \n",
    "\n",
    "You might want to create a symlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ln -s /path/to/your/imagenet/folder/ imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IBA.pytorch import IBA, tensor_to_np_img, get_imagenet_folder, imagenet_transform\n",
    "from IBA.utils import plot_saliency_map, to_unit_interval, load_monkeys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vgg16\n",
    "import torch\n",
    "\n",
    "# points to the imagenet validation dir\n",
    "imagenet_dir = 'imagenet/validation'\n",
    "\n",
    "# Load model\n",
    "dev = 'cuda:0' if  torch.cuda.is_available() else 'cpu'\n",
    "model = vgg16(pretrained=True)\n",
    "model.to(dev)\n",
    "\n",
    "# Add a Per-Sample Bottleneck at layer conv4_1\n",
    "iba = IBA(model.features[17])\n",
    "\n",
    "# Estimate the mean and variance of the feature map at this layer.\n",
    "val_set = get_imagenet_folder(imagenet_dir)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "iba.estimate(model, val_loader, n_samples=5000, progbar=True)\n",
    "\n",
    "# Load Image\n",
    "monkeys, target = load_monkeys(pil=True)\n",
    "monkeys_transform = imagenet_transform()(monkeys)\n",
    "\n",
    "# Closure that returns the loss for one batch\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), dim=1)[:, target].mean()\n",
    "\n",
    "# Explain class target for the given image\n",
    "saliency_map = iba.analyze(monkeys_transform.unsqueeze(0).to(dev), model_loss_closure, beta=10)\n",
    "\n",
    "# display result\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "heatmap = iba.analyze(monkeys_transform[None].to(dev), model_loss_closure ) \n",
    "plot_saliency_map(heatmap, tensor_to_np_img(monkeys_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfv1]",
   "language": "python",
   "name": "conda-env-tfv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
