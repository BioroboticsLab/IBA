{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: IBA (Per-Sample Bottleneck)\n",
    "\n",
    "This notebook shows how to apply the Per-Sample Bottleneck to pretrained ImageNet models. \n",
    "\n",
    "Ensure that `./imagenet` points to your copy of the ImageNet dataset. \n",
    "\n",
    "You might want to create a symlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ln -s /path/to/your/imagenet/folder/ imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IBA.tensorflow_v1 import IBACopyInnvestigate, model_wo_softmax, get_imagenet_generator\n",
    "from IBA.utils import load_monkeys, plot_saliency_map\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from assert_cache import assert_cache, get_asserted_values\n",
    "import numpy as np\n",
    "from IBA.utils import to_unit_interval\n",
    "\n",
    "import keras.backend as K\n",
    "from tqdm.auto import tqdm as tqdmbar\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_(key, obj, assertion_fn, message_fn=None):\n",
    "    assert_cache(\"tensorflow\", key, obj, assertion_fn, message_fn)\n",
    "    \n",
    "assert_(\"1\", 2, \n",
    "        lambda a, b: a == b, \n",
    "        lambda a, b: \"seriously? {} != {}\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_softmax = VGG16(weights='imagenet')\n",
    "\n",
    "# remove the final softmax layer\n",
    "model = model_wo_softmax(model_softmax)\n",
    "\n",
    "# select layer after which the bottleneck will be inserted\n",
    "feat_layer = model.get_layer(name='block4_conv1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms \n",
    "\n",
    "class PatternTransform(object):\n",
    "    # only work for VGG16\n",
    "    def __init__(self):\n",
    "        self.scale = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "        ])\n",
    "        self.offset = np.array([103.939, 116.779, 123.68])[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    def __call__(self, raw_img):\n",
    "        scaled_img = self.scale(raw_img)\n",
    "        ret = np.array(scaled_img, dtype=np.float)\n",
    "        # Channels first\n",
    "        ret = ret.transpose((2, 0, 1))\n",
    "        # Remove pixel-wise mean.\n",
    "        # To BGR.\n",
    "        ret = ret[::-1, :, :]\n",
    "        ret -= self.offset\n",
    "        return np.ascontiguousarray(ret.transpose(1, 2, 0))\n",
    "    \n",
    "def np_collate(batch):\n",
    "    imgs = [b[0] for b in batch]\n",
    "    targets = [b[1] for b in batch]\n",
    "    return np.stack(imgs), np.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Lambda\n",
    "\n",
    "\n",
    "def get_imagenet_folder(path, image_size=224, transform='default'):\n",
    "    \"\"\"\n",
    "    Returns a ``torchvision.datasets.ImageFolder`` with the default\n",
    "    torchvision preprocessing.\n",
    "    \"\"\"\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision.datasets import ImageFolder\n",
    "    from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize, Normalize\n",
    "    if transform == 'default':\n",
    "        transform = Compose([\n",
    "            CenterCrop(256), Resize(image_size), ToTensor(),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "    return ImageFolder(path, transform=transform)\n",
    "\n",
    "\n",
    "val_set = get_imagenet_folder('/srv/public/leonsixt/data/imagenet/validation')\n",
    "\n",
    "pattern_val_set = get_imagenet_folder(\n",
    "    '/srv/public/leonsixt/data/imagenet/validation', \n",
    "    transform=PatternTransform(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_val_loader = DataLoader(pattern_val_set, batch_size=50, \n",
    "                                shuffle=False, num_workers=4,\n",
    "                                collate_fn=np_collate)\n",
    "\n",
    "pattern_val_loader_shuffle = DataLoader(pattern_val_set, batch_size=50, \n",
    "                                shuffle=True, num_workers=4,\n",
    "                                collate_fn=np_collate)\n",
    "imgs, logits = next(iter(pattern_val_loader))\n",
    "imgs2, logits = next(iter(pattern_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs == imgs2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_(\"first_image_batch_equal\", imgs, \n",
    "        lambda a, b: np.abs((a - b)).mean() < 1e-4,\n",
    "        lambda a, b: np.abs((a - b)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transpose_idxs = [26, 28, 30]        \n",
    "\n",
    "npz_weights = np.load(\"vgg_16_weights.npz\") \n",
    "\n",
    "for i, weight in enumerate(model.weights):\n",
    "    arr = npz_weights['arr_' + str(i)]\n",
    "    arr = arr.T\n",
    "    if i in transpose_idxs:\n",
    "        arr = arr.T\n",
    "    if len(arr.shape) == 4:\n",
    "        arr = arr.transpose(1, 0, 2, 3)\n",
    "    #print('l', arr.shape)\n",
    "    #print('w', weight.shape)\n",
    "    diff = np.abs(weight.eval(K.get_session()) - arr).mean()\n",
    "    if diff != 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(weight.eval(K.get_session()).T)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(arr.T)\n",
    "        print(i, diff, arr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for framework, val in get_asserted_values(\"first_image_batch_equal\").items():\n",
    "    print(framework, val.mean(), val.std())\n",
    "    print(framework, val.min(), val.max())\n",
    "    plt.imshow(to_unit_interval(val[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_(\"first_batch_outputs_equal\", outputs, \n",
    "        lambda a, b: np.abs((a - b)).mean() < 1e-4,\n",
    "        lambda a, b: np.abs((a - b)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, val in get_asserted_values(\"first_batch_outputs_equal\").items():\n",
    "    print(name, val.min(), val.max())\n",
    "    plt.hist(val.flatten())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "logits = []\n",
    "progbar = tqdmbar(pattern_val_loader)\n",
    "for img, target in progbar:\n",
    "    logit = model.predict(img)\n",
    "    correct.append(np.argmax(logit, 1) == target)\n",
    "    logits.append(logit)\n",
    "    progbar.set_postfix(acc=np.concatenate(correct).mean())\n",
    "    #if len(logits) == 100:\n",
    "    if len(logits) == 1:\n",
    "        break\n",
    "logits = np.concatenate(logits)\n",
    "correct = np.concatenate(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert_(\"corrects_equal\", correct, \n",
    "#         lambda a, b: (a == b).mean(),\n",
    "#         lambda a, b: (a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_layer.kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies the model\n",
    "iba = IBACopyInnvestigate(\n",
    "    model,\n",
    "    neuron_selection_mode='index',\n",
    "    feature_name=feat_layer.output.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate feature mean and std\n",
    "n_samples = 50\n",
    "iba.fit_generator(pattern_val_loader, \n",
    "                  steps_per_epoch=n_samples // pattern_val_loader.batch_size)\n",
    "\n",
    "\n",
    "assert_('estimated_mean_1', iba._estimator.mean(),\n",
    "        lambda a, b: np.abs(a - b).mean() < 1e-4,\n",
    "        lambda a, b: (a.mean(), b.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    iba._estimator.reset()\n",
    "    iba.fit_generator(pattern_val_loader, \n",
    "                      steps_per_epoch=i, verbose=0)\n",
    "\n",
    "    assert_(f'estimated_mean_{i*pattern_val_loader.batch_size}',\n",
    "            iba._estimator.mean(),\n",
    "            lambda a, b: np.abs(a - b).mean() < 1e-3,\n",
    "            lambda a, b: (a.mean(), b.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_means = get_asserted_values('estimated_mean')\n",
    "plt.hist((estim_means['tensorflow'] - estim_means['pytorch']).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(estim_means['tensorflow'].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate feature mean and std\n",
    "n_samples = 5000\n",
    "iba._estimator.reset()\n",
    "iba.fit_generator(pattern_val_loader_shuffle, \n",
    "                  steps_per_epoch=n_samples // pattern_val_loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkeys, target = load_monkeys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba.set_default(beta=10, min_std=0, smooth_std=0, steps=10)\n",
    "iba.collect_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkeys_scaled =  preprocess_input(monkeys)\n",
    "\n",
    "# get the saliency map and plot\n",
    "saliency_map = iba.analyze(monkeys_scaled[None], neuron_selection=target)\n",
    "plot_saliency_map(saliency_map, img=monkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = iba.get_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report['init']['grad_loss_wrt_alpha'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(report['init']['grad_loss_wrt_alpha'].flatten(), bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_('grad_alpha_0',\n",
    "        report[0]['grad_loss_wrt_alpha'], \n",
    "        lambda s, o: np.abs(s-o).mean() < 1e-6,\n",
    "        lambda s, o: (s.mean(), s.std(), o.mean(), o.std())\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(report[0]['grad_loss_wrt_alpha']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[it['model_loss'] for it in report.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report[9]['information_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = report['final']['capacity']\n",
    "print(np.isnan(capacity).sum())\n",
    "capacity.shape\n",
    "plt.imshow(np.nansum(capacity[0], -1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = report[0]['capacity_no_nans']\n",
    "np.isnan(capacity).sum()\n",
    "capacity.shape\n",
    "plt.imshow(np.isnan(capacity[0]).sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = iba._estimator.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean.sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = report['init']['feature_mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = iba._active_neurons.eval(iba._session)\n",
    "active.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((1-active[0]).sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_mask = 1 - report['init']['pass_mask']\n",
    "restrict_mask.sum() == np.prod(restrict_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report['init']['capacity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report['final']['capacity'][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(report['final']['capacity'][0].flatten(), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(iba._estimator.mean().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(iba._estimator.std().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = list(report.keys())\n",
    "plt.plot(iters, [vals['information_loss'] for it, vals in report.items()], label='info')\n",
    "plt.plot(iters, [vals['model_loss'] for it, vals in report.items()], label='model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(report['final']['alpha'].flatten(), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report['final']['capacity'][0].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(monkeys_scaled.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IBA.utils import load_monkeys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(load_monkeys()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfv1]",
   "language": "python",
   "name": "conda-env-tfv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
