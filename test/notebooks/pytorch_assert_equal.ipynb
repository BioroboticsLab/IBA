{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need the saved tensorflow weights from: https://drive.google.com/open?id=1HdSyCFzJlzJ2mFo_ZClSVCA1nJJpwAmg\n",
    "```\n",
    "$ sha256sum vgg_16_weights.npz                  \n",
    "```\n",
    "Should give\n",
    "```\n",
    "ff50e3f93d9cf158f31d1cc4275cfd477e37dcc4fdcdc8c9266decdcc561b049  vgg_16_weights.npz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm as tqdmbar\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "\n",
    "\n",
    "from load_tensorflow_vgg_weights import TensorflowVGGWeights, TensorflowTransform\n",
    "\n",
    "from IBA.pytorch import IBA, tensor_to_np_img, get_imagenet_folder\n",
    "from IBA.utils import plot_saliency_map, to_unit_interval\n",
    "\n",
    "\n",
    "from IBA.utils import load_monkeys\n",
    "import torch.nn.functional as F\n",
    "import PIL\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from assert_cache import assert_cache, get_assert_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_dir = \"asserts\"\n",
    "\n",
    "def to_nhwc(x):\n",
    "    return x.transpose(0, 2, 3, 1)\n",
    "\n",
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def assert_(key, obj, assertion_fn, message_fn=None):\n",
    "    if type(obj) == torch.Tensor:\n",
    "        obj = obj.detach().cpu().numpy()\n",
    "    if type(obj) == np.ndarray and len(obj.shape) == 4:\n",
    "        obj = to_nhwc(obj)\n",
    "    assert_cache(\"pytorch\", key, obj, assertion_fn, message_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_assert_file(\"pytorch\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_(\"1\", 2, \n",
    "        lambda a, b: a == b, \n",
    "        lambda a, b: \"seriously? {} != {}\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some pre-trained model to analyze\n",
    "dev = 'cuda:0' if  torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load model\n",
    "tf_weights = TensorflowVGGWeights('cuda:0')\n",
    "model = tf_weights.get_model()\n",
    "\n",
    "#model = vgg16(pretrained=True)\n",
    "#model.to(dev)\n",
    "\n",
    "# setup data loader\n",
    "val_set = get_imagenet_folder('/srv/public/leonsixt/data/imagenet/validation')\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "pattern_val_set = get_imagenet_folder(\n",
    "    '/srv/public/leonsixt/data/imagenet/validation',  \n",
    "    transform=TensorflowTransform()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_val_loader = DataLoader(pattern_val_set, batch_size=50, \n",
    "                                shuffle=False, num_workers=4)\n",
    "pattern_val_loader_shuffle = DataLoader(pattern_val_set, batch_size=50, \n",
    "                                shuffle=True, num_workers=4)\n",
    "imgs, logits = next(iter(pattern_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_unit_interval(to_nhwc(to_np(imgs))[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "assert_(\"first_image_batch_equal\", imgs, lambda a, b: np.abs(a - b).mean() < 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(imgs.to(dev))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.min(), outputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_(\"first_batch_outputs_equal\", outputs, \n",
    "        lambda a, b: np.abs((a - b)).mean() < 1e-4,\n",
    "        lambda a, b: np.abs((a - b)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "logits = []\n",
    "with torch.no_grad():\n",
    "    progbar = tqdmbar(pattern_val_loader)\n",
    "    for img, target in progbar:\n",
    "        logit = model(img.to(dev))\n",
    "\n",
    "        correct.append(torch.argmax(logit, 1).cpu() == target)\n",
    "        logits.append(logit.cpu().numpy())\n",
    "        progbar.set_postfix(acc=torch.cat(correct).float().mean().item())\n",
    "        if len(logits) == 100:\n",
    "            break\n",
    "            \n",
    "logits = np.concatenate(logits)\n",
    "correct = np.concatenate(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_(\"corrects_equal\", correct, \n",
    "        lambda a, b: (a == b).mean(),\n",
    "        lambda a, b: (a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _ = next(iter(pattern_val_loader))\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check IBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_layer = model.features[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'iba' in globals():\n",
    "    iba.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Per-Sample Bottleneck at layer conv4_1\n",
    "iba = IBA(explained_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_val_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the mean and variance of the feature map at this layer.\n",
    "iba.estimate(model, pattern_val_loader, n_samples=5, progbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_('estimated_mean_1', iba.estimator.mean().permute(1, 2, 0),\n",
    "        lambda a, b: np.abs(a - b).mean() < 1e-4,\n",
    "        lambda a, b: (a.mean(), b.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    iba.estimate(model, pattern_val_loader, \n",
    "                 n_samples=i*50 - 5,  progbar=False, reset=True)\n",
    "    assert_('estimated_mean_' + str(50*i), \n",
    "            iba.estimator.mean().permute(1, 2, 0),\n",
    "            lambda a, b: np.abs(a - b).mean() < 1e-4,\n",
    "            lambda a, b: (a.mean(), b.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba.estimate(model, pattern_val_loader_shuffle, \n",
    "             n_samples=5000 - 1,  progbar=False, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closure that returns the loss for one batch\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), dim=1)[:, target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain class target for the given image\n",
    "\n",
    "img, target = pattern_val_set[0]\n",
    "target = 2\n",
    "\n",
    "def model_loss(x):\n",
    "    logits = model(x)\n",
    "    target_torch = torch.LongTensor([target] * len(logits)).to(dev)\n",
    "    return F.cross_entropy(logits, target_torch)\n",
    "\n",
    "saliency_map = iba.analyze(img.unsqueeze(0).to(dev), \n",
    "                                   model_loss, beta=10)\n",
    "\n",
    "# display result\n",
    "np_img = to_unit_interval(tensor_to_np_img(img))\n",
    "plot_saliency_map(saliency_map, np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(x):\n",
    "    logits = model(x)\n",
    "    target_torch = torch.LongTensor([target] * len(logits)).to(dev)\n",
    "    return F.cross_entropy(logits, target_torch)\n",
    "\n",
    "monkeys, target = load_monkeys(pil=True)\n",
    "monkeys_trans = TensorflowTransform()(monkeys)\n",
    "\n",
    "saliency_map = iba.analyze(monkeys_trans.unsqueeze(0).to(dev), \n",
    "                           model_loss, beta=10, \n",
    "                           lr=1,\n",
    "                           min_std=0,\n",
    "                           optimization_steps=10)\n",
    "\n",
    "# display result\n",
    "np_img = to_unit_interval(tensor_to_np_img(monkeys_trans))\n",
    "plot_saliency_map(saliency_map, np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba._alpha_grads[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(iba._alpha_grads[0].flatten(), bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_('grad_alpha_0',\n",
    "        iba._alpha_grads[0].transpose(1, 2, 0), \n",
    "        lambda s, o: np.abs(s-o).mean() < 1e-6,\n",
    "        lambda s, o: (s.mean(), s.std(), o.mean(), o.std())\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = iba._buffer_capacity.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(capacity[0].sum(0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = iba.estimator.mean().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean.sum(0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active = iba._active_neurons.cpu().numpy()\n",
    "print(active.shape)\n",
    "plt.imshow((1- active).sum(0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba._model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(pattern_iba._loss, label='loss')\n",
    "plt.plot(iba._information_loss, label='info')\n",
    "plt.plot(iba._model_loss, label='model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pattern_iba.alpha.detach().cpu().numpy()\n",
    "plt.hist(alpha.flatten(), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = pattern_iba.capacity().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(capacity.flatten(), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(capacity.sum(0).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pattern_iba.estimator.mean().cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pattern_iba.estimator.std().cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Per-Sample Bottleneck at layer conv4_1\n",
    "iba = IBA(model.features[17])\n",
    "\n",
    "# Estimate the mean and variance of the feature map at this layer.\n",
    "iba.estimate(model, val_loader, n_samples=5000, progbar=True)\n",
    "\n",
    "\n",
    "# Closure that returns the loss for one batch\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), dim=1)[:, target].mean()\n",
    "\n",
    "# Explain class target for the given image\n",
    "img, target = val_set[0]\n",
    "saliency_map = iba.analyze(img.unsqueeze(0).to(dev), model_loss_closure, beta=10)\n",
    "\n",
    "# display result\n",
    "np_img = to_unit_interval(tensor_to_np_img(img))\n",
    "plot_saliency_map(saliency_map, np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfv1]",
   "language": "python",
   "name": "conda-env-tfv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
