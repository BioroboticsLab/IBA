{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow: IBACopyInnvestigate \n",
    "\n",
    "This notebook shows how to use the [innvestigate](https://github.com/albermax/innvestigate) API wrapper. \n",
    "The [innvestiage](https://github.com/albermax/innvestigate) API is handy for classification models. \n",
    "For more complex models, you should either use the `IBACopyGraph` analyzer or embedd the `IBALayer` \n",
    "directly into your model.\n",
    "\n",
    "Ensure that `./imagenet` points to your copy of the ImageNet dataset. \n",
    "\n",
    "You might want to create a symlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ln -s /path/to/your/imagenet/folder/ imagenet \n",
    "! ln -s /srv/public/leonsixt/data/imagenet/ imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select your device\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# reduce tensorflow noise\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from keras.applications import VGG16, MobileNetV2\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from IBA.utils import plot_saliency_map\n",
    "from IBA.tensorflow_v1 import IBACopyInnvestigate, TFWelfordEstimator, model_wo_softmax, to_saliency_map \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}, Keras version: {}\".format(\n",
    "    tf.version.VERSION, keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "\n",
    "def get_val_iter(val_dir, image_size = (224, 224), shuffle=True, batch_size=50):\n",
    "    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    return image_generator.flow_from_directory(\n",
    "        val_dir, shuffle=shuffle, seed=0, batch_size=batch_size, target_size=image_size)\n",
    "\n",
    "def norm_image(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "imagenet_dir = \"./imagenet\"\n",
    "imagenet_val_dir = os.path.join(imagenet_dir, \"validation\")\n",
    "\n",
    "img_batch, target_batch = next(get_val_iter(imagenet_val_dir))\n",
    "\n",
    "monkey_pil = Image.open(\"monkeys.jpg\").resize((224, 224))\n",
    "monkey = preprocess_input(np.array(monkey_pil))[None]\n",
    "monkey_target = 382  # 382: squirrel monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model_softmax = VGG16(weights='imagenet')\n",
    "\n",
    "# make sure you remove the final softmax layer\n",
    "model = model_wo_softmax(model_softmax)\n",
    "\n",
    "# select layer after which the bottleneck will be inserted \n",
    "feat_layer = model.get_layer(name='block4_conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba = IBACopyInnvestigate(\n",
    "    model,\n",
    "    neuron_selection_mode='index',\n",
    "    feature_name=feat_layer.output.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check if model was copied correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba_logits = iba.predict(img_batch)\n",
    "model_logits = model.predict(img_batch)\n",
    "assert np.abs(iba_logits - model_logits).mean() < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit mean and std of the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iba.fit_generator(get_val_iter(imagenet_val_dir), steps_per_epoch=50)\n",
    "print(\"Fitted estimator on {} samples\".format(iba._estimator.n_samples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the saliency map \n",
    "saliency_map = iba.analyze(monkey, neuron_selection=monkey_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency_map(saliency_map, img=norm_image(monkey[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to internal values \n",
    "\n",
    "You can access all intermediate values of the optimzation through the `iba.get_report()` method.\n",
    "To store the intermediate values, you have to call either `iba.collect_all()` or `iba.collect(*var_names)` before running `iba.analyze(..)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all intermediate tensors\n",
    "iba.collect_all()\n",
    "\n",
    "# alternatively, you can select a view tensors\n",
    "# iba.collect(\"alpha\", \"model_loss\")\n",
    "# to only collect a subset all all tensors\n",
    "\n",
    "# get the saliency map \n",
    "saliency_map = iba.analyze(monkey, neuron_selection=monkey_target)\n",
    "\n",
    "# get all saved outputs\n",
    "report = iba.get_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`report` is an `OrderedDict`  which maps each `iteration` to a dictionray of `{var_name, var_value}`.\n",
    "The `init` iteration is computed without an optimizer update. Values not changing such as the feature values are only included in the `init` iteration.\n",
    "The `final` iteration is again computed without an optimizer update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"iterations:\", list(report.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Print all available tensors in the `init` iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<30} {:}\".format(\"name:\", \"shape\"))\n",
    "print()\n",
    "for name, val in report['init'].items():\n",
    "    print(\"{:<30} {:}\".format(name + \":\", str(val.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "ax[0].set_title(\"cross entrop loss\")\n",
    "ax[0].plot(list(report.keys()), [it['model_loss'] for it in report.values()])\n",
    "\n",
    "ax[1].set_title(\"mean capacity\")\n",
    "ax[1].plot(list(report.keys()), [it['capacity_mean'] for it in report.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Distribution of alpha (pre-softmax) values per iteraton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 6\n",
    "rows = len(report) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(2.8*cols, 2.2*rows))\n",
    "\n",
    "for ax, (it, values) in zip(axes.flatten(), report.items()):\n",
    "    ax.hist(values['alpha'].flatten(), log=True, bins=20)\n",
    "    ax.set_title(\"iteration: \" + str(it))\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "fig.suptitle(\"distribution of alpha (pre-softmax) values per iteraton.\", y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributiuon of the final capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(report['final']['capacity'].flatten(), bins=20, log=True)\n",
    "plt.title(\"Distributiuon of the final capacity\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfv1]",
   "language": "python",
   "name": "conda-env-tfv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
