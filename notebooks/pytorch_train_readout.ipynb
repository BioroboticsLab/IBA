{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readout Bottleneck \n",
    "\n",
    "This notebook shows how to train the Readout Bottleneck and apply it to a pretrained ImageNet model. \n",
    "\n",
    "Ensure that `./imagenet` points to your copy of the ImageNet dataset. \n",
    "\n",
    "You might want to create a symlink:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ln -s /path/to/your/imagenet/folder/ imagenet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize, Normalize\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "try:\n",
    "    import IBA\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.insert(0, '..')\n",
    "    import IBA\n",
    "    \n",
    "from IBA.pytorch_readout import IBAReadout\n",
    "from IBA.pytorch import tensor_to_np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_dir = './imagenet'\n",
    "\n",
    "dev = torch.device('cuda:0')\n",
    "\n",
    "model = torchvision.models.vgg16(pretrained=True).to(dev)\n",
    "\n",
    "valset = ImageFolder(\n",
    "    os.path.join(imagenet_dir, 'validation'),\n",
    "    transform=Compose([\n",
    "        CenterCrop(256), Resize(224), ToTensor(), \n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "trainset = ImageFolder(\n",
    "    os.path.join(imagenet_dir, 'train'),\n",
    "    transform=Compose([\n",
    "        CenterCrop(256), Resize(224), ToTensor(), \n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "with open('imagenet_class_index.json') as f:\n",
    "    idx2class = {int(k): v[1] for k, v in json.load(f).items()}\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "img, target = valset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the bottleneck into the model\n",
    "\n",
    "You can experiment with layers to read and the location of the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a set of layers to read. \n",
    "readout_layers = [\n",
    "    model.features[10],\n",
    "    model.features[14],\n",
    "    model.features[18],\n",
    "    model.features[28],\n",
    "    model.classifier,\n",
    "]\n",
    "\n",
    "# Initialize the Readout Bottleneck and inject it to the 10-th layer\n",
    "btln = IBAReadout(model.features[10], readout_layers, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Mean and Variance\n",
    "\n",
    "Here, we estimate the mean and variances of the feature map. It is important for measuring the amount of information transmitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btln.estimate(model, trainloader, device=dev, n_samples=10000, progbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Readout Network\n",
    "\n",
    "We train the mapping from readout feature maps to alphas on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: We only train the parameters of the\n",
    "# Readout Bottleneck - the model remains frozen\n",
    "optimizer = torch.optim.Adam(lr=1e-5, params=btln.parameters())\n",
    "beta = 10\n",
    "\n",
    "# Train for 10 epochs, this may take some time. \n",
    "# You may interrupt earlier to inspect intermediate results.\n",
    "with btln.supress_information():\n",
    "    for epoch in range(10):\n",
    "        for x, target in tqdm(trainloader, desc=f\"Training epoch {epoch}\"):\n",
    "            x, target = x.to(dev), target.to(dev)\n",
    "            optimizer.zero_grad()\n",
    "            model_loss = -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "            information_loss = btln.capacity().mean()\n",
    "            loss = model_loss + beta * information_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Heatmaps for some random samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IBA.utils import plot_saliency_map\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 6))\n",
    "np.random.seed(0)\n",
    "for ax, sample_idx in zip(axes.flatten(), np.random.choice(50000, 10)):\n",
    "    img, target = valset[sample_idx]\n",
    "    img = img[None].to(dev)\n",
    "    \n",
    "    # Execute the model on a given sample and return the target NLL\n",
    "    model_loss_closure = lambda x: -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "    \n",
    "    # Generate the heatmap\n",
    "    heatmap = btln.analyze(img, model_loss_closure)\n",
    "    \n",
    "    # Reverse the data pre-processing for plotting the original image\n",
    "    np_img = tensor_to_np_img(img[0])\n",
    "    \n",
    "    # Show the heatmap\n",
    "    plot_saliency_map(heatmap, np_img,  ax=ax)\n",
    "    ax.set_title(idx2class[target])\n",
    "    \n",
    "fig.suptitle(\"model: {}\".format(type(model).__name__))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = np.array(Image.open(\"./monkeys.jpg\"))\n",
    "img = (img.transpose(2, 0, 1) / 255)\n",
    "target = 382  # 382: squirrel monkey\n",
    "\n",
    "# preprocess image\n",
    "img  = Compose([\n",
    "    Resize(224), ToTensor(),  \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])(Image.open(\"./monkeys.jpg\"))\n",
    "\n",
    "model_loss_closure = lambda x: -torch.log_softmax(model(x), 1)[:, target].mean()\n",
    "heatmap = btln.analyze(img[None].to(dev), model_loss_closure) \n",
    "ax = plot_saliency_map(heatmap, tensor_to_np_img(img))\n",
    "_ = ax.set_title(idx2class[target])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
